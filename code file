{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1dyBz59IDok",
        "outputId": "14460a15-5077-468a-9e1a-da963a3c2713"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "TUMOR SEGMENTATION - GOOGLE COLAB\n",
            "================================================================================\n",
            "\n",
            "‚úì CUDA cache cleared\n",
            "  GPU: Tesla T4\n",
            "  Memory: 15.83 GB\n",
            "\n",
            "‚öôÔ∏è Configuration:\n",
            "  Platform: Google Colab\n",
            "  Data directory: /content/drive/MyDrive/Brain_tumor\n",
            "  Output directory: /content/tumor_segmentation_results\n",
            "  Models to train: maskrcnn, unet\n",
            "  Device: cuda\n",
            "  Image size: 416x416\n",
            "  Batch size: 2\n",
            "  Epochs: 20\n",
            "  Learning rate: 0.001\n",
            "\n",
            "‚è±Ô∏è  Estimated training time: ~1-2 hours on T4 GPU\n",
            "\n",
            "================================================================================\n",
            "LOADING DATASET\n",
            "================================================================================\n",
            "\n",
            "‚úì Dataset loaded:\n",
            "  Training: 1502 images\n",
            "  Validation: 429 images\n",
            "  Testing: 215 images\n",
            "\n",
            "================================================================================\n",
            "INITIALIZING MASKRCNN MODEL\n",
            "================================================================================\n",
            "  Loading pretrained Mask R-CNN...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MaskRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=MaskRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [00:00<00:00, 181MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Moving model to cuda...\n",
            "  Testing model with dummy input...\n",
            "  ‚úì Model loaded successfully!\n",
            "\n",
            "‚úì Model created and moved to cuda\n",
            "\n",
            "================================================================================\n",
            "TRAINING MASKRCNN\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [15:05<00:00,  1.21s/it]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [03:29<00:00,  1.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.5020 | Valid Loss: 0.4006\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:37<00:00,  2.22it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:43<00:00,  4.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.3673 | Valid Loss: 0.3790\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "Epoch 3/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:38<00:00,  2.22it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:43<00:00,  4.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.3247 | Valid Loss: 0.3760\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "Epoch 4/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:39<00:00,  2.21it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:44<00:00,  4.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.2792 | Valid Loss: 0.3711\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "Epoch 5/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:40<00:00,  2.21it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:43<00:00,  4.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.2395 | Valid Loss: 0.3894\n",
            "\n",
            "Epoch 6/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:40<00:00,  2.20it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:43<00:00,  4.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.2107 | Valid Loss: 0.4166\n",
            "\n",
            "Epoch 7/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:41<00:00,  2.20it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:44<00:00,  4.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1836 | Valid Loss: 0.4475\n",
            "\n",
            "Epoch 8/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:41<00:00,  2.20it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:44<00:00,  4.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1637 | Valid Loss: 0.4259\n",
            "\n",
            "Epoch 9/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:41<00:00,  2.20it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:44<00:00,  4.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1438 | Valid Loss: 0.4710\n",
            "\n",
            "Epoch 10/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:41<00:00,  2.20it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:44<00:00,  4.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1307 | Valid Loss: 0.4929\n",
            "\n",
            "Epoch 11/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:42<00:00,  2.19it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:44<00:00,  4.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1077 | Valid Loss: 0.5233\n",
            "\n",
            "Epoch 12/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:41<00:00,  2.20it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:44<00:00,  4.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0948 | Valid Loss: 0.5464\n",
            "\n",
            "Epoch 13/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:42<00:00,  2.20it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:44<00:00,  4.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0881 | Valid Loss: 0.5659\n",
            "\n",
            "Epoch 14/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:41<00:00,  2.20it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:44<00:00,  4.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0828 | Valid Loss: 0.5830\n",
            "\n",
            "Epoch 15/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:41<00:00,  2.20it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:44<00:00,  4.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0789 | Valid Loss: 0.6009\n",
            "\n",
            "Epoch 16/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:42<00:00,  2.19it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:44<00:00,  4.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0757 | Valid Loss: 0.6121\n",
            "\n",
            "Epoch 17/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:42<00:00,  2.19it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:44<00:00,  4.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0732 | Valid Loss: 0.6332\n",
            "\n",
            "Epoch 18/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:42<00:00,  2.19it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:43<00:00,  4.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0709 | Valid Loss: 0.6372\n",
            "\n",
            "Epoch 19/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:42<00:00,  2.19it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:43<00:00,  4.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0690 | Valid Loss: 0.6488\n",
            "\n",
            "Epoch 20/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [05:42<00:00,  2.20it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [00:43<00:00,  4.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0676 | Valid Loss: 0.6594\n",
            "\n",
            "================================================================================\n",
            "EVALUATING MASKRCNN\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [01:55<00:00,  1.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úì Evaluation Results for MASKRCNN:\n",
            "  Mean IoU: 0.5944 ¬± 0.2743\n",
            "  Mean Dice: 0.6986 ¬± 0.2781\n",
            "  Mean Precision: 0.7126 ¬± 0.3279\n",
            "  Mean Recall: 0.7524 ¬± 0.2738\n",
            "  Mean F1-Score: 0.6986 ¬± 0.2781\n",
            "  Tested on 215 images\n",
            "\n",
            "Creating prediction visualizations for MASKRCNN...\n",
            "‚úì Fig6: MASKRCNN predictions saved (PNG)\n",
            "\n",
            "‚úì Memory cleared after MASKRCNN\n",
            "\n",
            "================================================================================\n",
            "INITIALIZING UNET MODEL\n",
            "================================================================================\n",
            "  Initializing U-Net...\n",
            "  Moving model to cuda...\n",
            "  Testing model with dummy input...\n",
            "  ‚úì Model loaded successfully!\n",
            "\n",
            "‚úì Model created and moved to cuda\n",
            "\n",
            "================================================================================\n",
            "TRAINING UNET\n",
            "================================================================================\n",
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [09:41<00:00,  1.29it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [01:01<00:00,  3.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1455 | Valid Loss: 0.1946\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [09:40<00:00,  1.29it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [01:01<00:00,  3.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1161 | Valid Loss: 0.2429\n",
            "\n",
            "Epoch 3/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [09:40<00:00,  1.29it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [01:02<00:00,  3.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.1041 | Valid Loss: 0.1105\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "Epoch 4/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [09:41<00:00,  1.29it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [01:02<00:00,  3.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0962 | Valid Loss: 0.1205\n",
            "\n",
            "Epoch 5/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [09:40<00:00,  1.29it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [01:01<00:00,  3.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0908 | Valid Loss: 0.1084\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "Epoch 6/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [09:40<00:00,  1.29it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [01:02<00:00,  3.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0845 | Valid Loss: 0.0875\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "Epoch 7/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [09:40<00:00,  1.29it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [01:02<00:00,  3.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0815 | Valid Loss: 0.1138\n",
            "\n",
            "Epoch 8/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [09:41<00:00,  1.29it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [01:02<00:00,  3.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0760 | Valid Loss: 0.1048\n",
            "\n",
            "Epoch 9/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [09:41<00:00,  1.29it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [01:02<00:00,  3.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0736 | Valid Loss: 0.0862\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "Epoch 10/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [09:40<00:00,  1.29it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [01:02<00:00,  3.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0703 | Valid Loss: 0.1311\n",
            "\n",
            "Epoch 11/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 751/751 [09:40<00:00,  1.29it/s]\n",
            "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215/215 [01:01<00:00,  3.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Train Loss: 0.0613 | Valid Loss: 0.0700\n",
            "  ‚úì Best model saved!\n",
            "\n",
            "Epoch 12/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 686/751 [08:50<00:50,  1.29it/s]"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Tumor Segmentation using Deep Learning - GOOGLE COLAB READY\n",
        "==============================================================\n",
        "\n",
        "Dataset: TumorSegmentation (COCO Segmentation format)\n",
        "- 2146 images (640x640)\n",
        "- Instance segmentation of tumors\n",
        "- Format: COCO JSON annotations\n",
        "\n",
        "Models supported:\n",
        "1. U-Net (baseline)\n",
        "2. Mask R-CNN (instance segmentation)\n",
        "3. DeepLabV3+ (semantic segmentation)\n",
        "\n",
        "GOOGLE COLAB SETUP:\n",
        "1. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save\n",
        "2. Mount Drive: Run the drive mount cell below\n",
        "3. Upload dataset to: /content/drive/MyDrive/brain-tumor/\n",
        "4. Run all cells\n",
        "\n",
        "IMPORTANT: If you get CUDA errors, restart the runtime!\n",
        "- In Colab: Runtime ‚Üí Restart Runtime ‚Üí Run all cells\n",
        "- In Kaggle: Kernel ‚Üí Restart Kernel ‚Üí Run all cells\n",
        "\"\"\"\n",
        "\n",
        "# ============================================================================\n",
        "# GOOGLE COLAB USERS: RUN THIS CELL FIRST (Uncomment the lines below)\n",
        "# ============================================================================\n",
        "# !pip install -q opencv-python-headless openpyxl\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# print(\"‚úì Google Drive mounted!\")\n",
        "# print(\"üìÅ Upload your dataset to: /content/drive/MyDrive/brain-tumor/\")\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_curve, auc, confusion_matrix\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Deep learning imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TUMOR SEGMENTATION - GOOGLE COLAB\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ==================== GOOGLE COLAB SETUP ====================\n",
        "# Uncomment and run these lines in Google Colab:\n",
        "# !pip install -q opencv-python-headless openpyxl\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# ================================================================\n",
        "\n",
        "# Clear CUDA cache and reset if needed\n",
        "try:\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "        print(f\"\\n‚úì CUDA cache cleared\")\n",
        "        print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    else:\n",
        "        print(f\"\\n‚ö† CUDA not available - using CPU (VERY SLOW!)\")\n",
        "        print(f\"  üí° TIP: Enable GPU in Colab:\")\n",
        "        print(f\"     Runtime ‚Üí Change runtime type ‚Üí GPU ‚Üí Save\")\n",
        "except RuntimeError as e:\n",
        "    print(f\"\\n‚ö†‚ö†‚ö† CUDA ERROR DETECTED ‚ö†‚ö†‚ö†\")\n",
        "    print(f\"  Error: {e}\")\n",
        "    print(f\"\\nüîÑ SOLUTION: You MUST restart the runtime first!\")\n",
        "    print(f\"\\n  In Google Colab:\")\n",
        "    print(f\"    1. Runtime ‚Üí Restart Runtime\")\n",
        "    print(f\"    2. Run all cells again\")\n",
        "    print(f\"\\n  In Kaggle:\")\n",
        "    print(f\"    1. Click 'Session Options' (gear icon)\")\n",
        "    print(f\"    2. Click 'Restart Session'\")\n",
        "    print(f\"    3. Run all cells again\")\n",
        "    print(f\"\\n  This clears previous CUDA errors.\")\n",
        "    print(\"=\"*80)\n",
        "    raise SystemExit(\"Please restart runtime and try again\")\n",
        "\n",
        "# ==================== CONFIGURATION ====================\n",
        "class Config:\n",
        "    # ========== PLATFORM SELECTION ==========\n",
        "    # Uncomment ONE of these based on where you're running:\n",
        "\n",
        "    # OPTION 1: Google Colab (with Google Drive)\n",
        "    DATA_DIR = \"/content/drive/MyDrive/Brain_tumor\"\n",
        "    OUTPUT_DIR = \"/content/tumor_segmentation_results\"\n",
        "\n",
        "    # OPTION 2: Kaggle\n",
        "    # DATA_DIR = \"/kaggle/input/brain-tumor-data\"\n",
        "    # OUTPUT_DIR = \"/kaggle/working/tumor_segmentation_results\"\n",
        "\n",
        "    # OPTION 3: Local Windows\n",
        "    # DATA_DIR = r\"D:\\NSU\\Semester_03\\ML\\Assignment\\Brain_tumor\"\n",
        "    # OUTPUT_DIR = r\"D:\\NSU\\Semester_03\\ML\\Assignment\\results\"\n",
        "\n",
        "    # OPTION 4: Local Linux/Mac\n",
        "    # DATA_DIR = \"/home/user/datasets/brain-tumor\"\n",
        "    # OUTPUT_DIR = \"/home/user/results\"\n",
        "\n",
        "    # ========================================\n",
        "\n",
        "    TRAIN_IMAGES = os.path.join(DATA_DIR, \"train\")\n",
        "    VALID_IMAGES = os.path.join(DATA_DIR, \"valid\")\n",
        "    TEST_IMAGES = os.path.join(DATA_DIR, \"test\")\n",
        "\n",
        "    TRAIN_ANNOTATIONS = os.path.join(DATA_DIR, \"train\", \"_annotations.coco.json\")\n",
        "    VALID_ANNOTATIONS = os.path.join(DATA_DIR, \"valid\", \"_annotations.coco.json\")\n",
        "    TEST_ANNOTATIONS = os.path.join(DATA_DIR, \"test\", \"_annotations.coco.json\")\n",
        "\n",
        "    # ========== MODEL PARAMETERS ==========\n",
        "    MODELS_TO_TRAIN = [\"maskrcnn\", \"unet\"]  # Train both models\n",
        "    # For faster training, use only one: [\"unet\"] or [\"maskrcnn\"]\n",
        "\n",
        "    NUM_CLASSES = 2  # Background + Tumor\n",
        "    IMG_SIZE = 416  # Use 416 for faster training, 640 for best accuracy\n",
        "    BATCH_SIZE = 2  # Increase to 4 if you have enough GPU memory\n",
        "    NUM_EPOCHS = 20  # Use 50 for best accuracy (takes longer)\n",
        "    LEARNING_RATE = 0.001\n",
        "\n",
        "    # Hardware - Auto-detect\n",
        "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    NUM_WORKERS = 2\n",
        "\n",
        "    # Evaluation\n",
        "    IOU_THRESHOLD = 0.5\n",
        "    CONFIDENCE_THRESHOLD = 0.5\n",
        "\n",
        "config = Config()\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è Configuration:\")\n",
        "print(f\"  Platform: {'Google Colab' if 'content' in config.DATA_DIR else 'Kaggle' if 'kaggle' in config.DATA_DIR else 'Local'}\")\n",
        "print(f\"  Data directory: {config.DATA_DIR}\")\n",
        "print(f\"  Output directory: {config.OUTPUT_DIR}\")\n",
        "print(f\"  Models to train: {', '.join(config.MODELS_TO_TRAIN)}\")\n",
        "print(f\"  Device: {config.DEVICE}\")\n",
        "print(f\"  Image size: {config.IMG_SIZE}x{config.IMG_SIZE}\")\n",
        "print(f\"  Batch size: {config.BATCH_SIZE}\")\n",
        "print(f\"  Epochs: {config.NUM_EPOCHS}\")\n",
        "print(f\"  Learning rate: {config.LEARNING_RATE}\")\n",
        "\n",
        "# Estimate training time\n",
        "if config.NUM_EPOCHS == 20 and len(config.MODELS_TO_TRAIN) == 2:\n",
        "    print(f\"\\n‚è±Ô∏è  Estimated training time: ~1-2 hours on T4 GPU\")\n",
        "elif config.NUM_EPOCHS == 50 and len(config.MODELS_TO_TRAIN) == 2:\n",
        "    print(f\"\\n‚è±Ô∏è  Estimated training time: ~4-5 hours on T4 GPU\")\n",
        "elif len(config.MODELS_TO_TRAIN) == 1:\n",
        "    print(f\"\\n‚è±Ô∏è  Estimated training time: ~30-60 min on T4 GPU\")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# ==================== DATASET CLASS ====================\n",
        "class TumorSegmentationDataset(Dataset):\n",
        "    def __init__(self, img_dir, annotation_file, transforms=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transforms = transforms\n",
        "\n",
        "        # Load COCO annotations\n",
        "        with open(annotation_file, 'r') as f:\n",
        "            self.coco_data = json.load(f)\n",
        "\n",
        "        self.images = self.coco_data['images']\n",
        "        self.annotations = self.coco_data['annotations']\n",
        "\n",
        "        # Create image_id to annotations mapping\n",
        "        self.img_to_anns = {}\n",
        "        for ann in self.annotations:\n",
        "            img_id = ann['image_id']\n",
        "            if img_id not in self.img_to_anns:\n",
        "                self.img_to_anns[img_id] = []\n",
        "            self.img_to_anns[img_id].append(ann)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load image\n",
        "        img_info = self.images[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_info['file_name'])\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Get annotations for this image\n",
        "        img_id = img_info['id']\n",
        "        anns = self.img_to_anns.get(img_id, [])\n",
        "\n",
        "        # Create masks and boxes\n",
        "        masks = []\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        for ann in anns:\n",
        "            # Get segmentation mask\n",
        "            if 'segmentation' in ann and len(ann['segmentation']) > 0:\n",
        "                # Convert polygon to mask\n",
        "                mask = self.polygon_to_mask(ann['segmentation'], img.shape[:2])\n",
        "\n",
        "                # Skip if mask is empty\n",
        "                if mask.sum() == 0:\n",
        "                    continue\n",
        "\n",
        "                masks.append(mask)\n",
        "\n",
        "                # Get bounding box\n",
        "                x, y, w, h = ann['bbox']\n",
        "\n",
        "                # Validate bounding box\n",
        "                if w <= 0 or h <= 0:\n",
        "                    continue\n",
        "\n",
        "                boxes.append([x, y, x + w, y + h])\n",
        "                # Mask R-CNN expects labels starting from 1 (0 is background)\n",
        "                # For binary classification (background vs tumor), all objects get label 1\n",
        "                labels.append(1)\n",
        "\n",
        "        # Convert to tensors\n",
        "        if len(masks) > 0:\n",
        "            masks = np.array(masks)\n",
        "            boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "            labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "            masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
        "        else:\n",
        "            # No annotations - create empty tensors\n",
        "            boxes = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            labels = torch.zeros((0,), dtype=torch.int64)\n",
        "            masks = torch.zeros((0, img.shape[0], img.shape[1]), dtype=torch.uint8)\n",
        "\n",
        "        # Create target dictionary\n",
        "        target = {\n",
        "            'boxes': boxes,\n",
        "            'labels': labels,\n",
        "            'masks': masks,\n",
        "            'image_id': torch.tensor([img_id])\n",
        "        }\n",
        "\n",
        "        # Apply transforms\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "        else:\n",
        "            img = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def polygon_to_mask(self, segmentation, img_shape):\n",
        "        \"\"\"Convert COCO polygon segmentation to binary mask\"\"\"\n",
        "        mask = np.zeros(img_shape, dtype=np.uint8)\n",
        "        for seg in segmentation:\n",
        "            poly = np.array(seg).reshape(-1, 2).astype(np.int32)\n",
        "            cv2.fillPoly(mask, [poly], 1)\n",
        "        return mask\n",
        "\n",
        "# ==================== MODEL DEFINITIONS ====================\n",
        "def get_maskrcnn_model(num_classes):\n",
        "    \"\"\"Get Mask R-CNN model for instance segmentation\"\"\"\n",
        "    model = maskrcnn_resnet50_fpn(pretrained=True)\n",
        "\n",
        "    # Replace the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    # Replace the mask predictor\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
        "\n",
        "    return model\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    \"\"\"U-Net architecture for semantic segmentation\"\"\"\n",
        "    def __init__(self, n_channels=3, n_classes=2):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        def conv_block(in_c, out_c):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_c, out_c, 3, padding=1),\n",
        "                nn.BatchNorm2d(out_c),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_c, out_c, 3, padding=1),\n",
        "                nn.BatchNorm2d(out_c),\n",
        "                nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = conv_block(n_channels, 64)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.enc2 = conv_block(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.enc3 = conv_block(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "        self.enc4 = conv_block(256, 512)\n",
        "        self.pool4 = nn.MaxPool2d(2)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = conv_block(512, 1024)\n",
        "\n",
        "        # Decoder\n",
        "        self.upconv4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
        "        self.dec4 = conv_block(1024, 512)\n",
        "        self.upconv3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
        "        self.dec3 = conv_block(512, 256)\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.dec2 = conv_block(256, 128)\n",
        "        self.upconv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec1 = conv_block(128, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(64, n_classes, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(self.pool1(enc1))\n",
        "        enc3 = self.enc3(self.pool2(enc2))\n",
        "        enc4 = self.enc4(self.pool3(enc3))\n",
        "\n",
        "        # Bottleneck\n",
        "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        dec4 = self.upconv4(bottleneck)\n",
        "        dec4 = torch.cat([dec4, enc4], dim=1)\n",
        "        dec4 = self.dec4(dec4)\n",
        "\n",
        "        dec3 = self.upconv3(dec4)\n",
        "        dec3 = torch.cat([dec3, enc3], dim=1)\n",
        "        dec3 = self.dec3(dec3)\n",
        "\n",
        "        dec2 = self.upconv2(dec3)\n",
        "        dec2 = torch.cat([dec2, enc2], dim=1)\n",
        "        dec2 = self.dec2(dec2)\n",
        "\n",
        "        dec1 = self.upconv1(dec2)\n",
        "        dec1 = torch.cat([dec1, enc1], dim=1)\n",
        "        dec1 = self.dec1(dec1)\n",
        "\n",
        "        return self.out(dec1)\n",
        "\n",
        "def get_model(model_type, num_classes, device):\n",
        "    \"\"\"Get the specified model\"\"\"\n",
        "    try:\n",
        "        if model_type == \"maskrcnn\":\n",
        "            print(\"  Loading pretrained Mask R-CNN...\")\n",
        "            model = get_maskrcnn_model(num_classes)\n",
        "        elif model_type == \"unet\":\n",
        "            print(\"  Initializing U-Net...\")\n",
        "            model = UNet(n_channels=3, n_classes=num_classes)\n",
        "        elif model_type == \"deeplabv3\":\n",
        "            print(\"  Loading pretrained DeepLabV3...\")\n",
        "            model = deeplabv3_resnet50(pretrained=True)\n",
        "            model.classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
        "\n",
        "        print(f\"  Moving model to {device}...\")\n",
        "        model = model.to(device)\n",
        "\n",
        "        # Test forward pass with dummy data\n",
        "        print(\"  Testing model with dummy input...\")\n",
        "        with torch.no_grad():\n",
        "            if model_type == \"maskrcnn\":\n",
        "                model.eval()\n",
        "                # Mask R-CNN expects a list of 3D tensors [C, H, W]\n",
        "                dummy_input = [torch.rand(3, 224, 224).to(device)]\n",
        "                _ = model(dummy_input)\n",
        "            else:\n",
        "                # U-Net and DeepLabV3 expect batched input [B, C, H, W]\n",
        "                dummy_input = torch.rand(1, 3, 224, 224).to(device)\n",
        "                _ = model(dummy_input)\n",
        "\n",
        "        print(\"  ‚úì Model loaded successfully!\")\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ö† ERROR loading model: {e}\")\n",
        "        print(\"  Clearing CUDA cache and retrying...\")\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Retry once\n",
        "        if model_type == \"maskrcnn\":\n",
        "            model = get_maskrcnn_model(num_classes)\n",
        "        elif model_type == \"unet\":\n",
        "            model = UNet(n_channels=3, n_classes=num_classes)\n",
        "        elif model_type == \"deeplabv3\":\n",
        "            model = deeplabv3_resnet50(pretrained=True)\n",
        "            model.classifier[4] = nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "\n",
        "        return model.to(device)\n",
        "\n",
        "# ==================== METRICS ====================\n",
        "def clear_memory():\n",
        "    \"\"\"Aggressively clear memory\"\"\"\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "def calculate_iou(pred_mask, gt_mask):\n",
        "    \"\"\"Calculate Intersection over Union\"\"\"\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    union = np.logical_or(pred_mask, gt_mask).sum()\n",
        "    if union == 0:\n",
        "        return 0.0\n",
        "    return intersection / union\n",
        "\n",
        "def calculate_dice(pred_mask, gt_mask):\n",
        "    \"\"\"Calculate Dice coefficient\"\"\"\n",
        "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
        "    if pred_mask.sum() + gt_mask.sum() == 0:\n",
        "        return 0.0\n",
        "    return 2 * intersection / (pred_mask.sum() + gt_mask.sum())\n",
        "\n",
        "# ==================== TRAINING ====================\n",
        "def train_maskrcnn(model, train_loader, valid_loader, config, model_name=\"maskrcnn\"):\n",
        "    \"\"\"Train Mask R-CNN model\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TRAINING {model_name.upper()}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=config.LEARNING_RATE,\n",
        "                                momentum=0.9, weight_decay=0.0005)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in range(config.NUM_EPOCHS):\n",
        "        print(f\"\\nEpoch {epoch+1}/{config.NUM_EPOCHS}\")\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        batch_count = 0\n",
        "        for images, targets in tqdm(train_loader, desc=\"Training\"):\n",
        "            try:\n",
        "                images = [img.to(config.DEVICE) for img in images]\n",
        "                targets = [{k: v.to(config.DEVICE) for k, v in t.items()} for t in targets]\n",
        "\n",
        "                # Filter out samples with no annotations\n",
        "                valid_samples = [(img, tgt) for img, tgt in zip(images, targets) if len(tgt['boxes']) > 0]\n",
        "\n",
        "                if len(valid_samples) == 0:\n",
        "                    continue\n",
        "\n",
        "                images, targets = zip(*valid_samples)\n",
        "                images = list(images)\n",
        "                targets = list(targets)\n",
        "\n",
        "                loss_dict = model(images, targets)\n",
        "                losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                losses.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += losses.item()\n",
        "                batch_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"\\n‚ö† Warning: Skipping batch due to error: {e}\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = epoch_loss / max(batch_count, 1)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation - need to keep model in training mode to get losses\n",
        "        model.train()  # Keep in train mode for validation to get loss values\n",
        "        epoch_val_loss = 0\n",
        "        val_batch_count = 0\n",
        "        with torch.no_grad():\n",
        "            for images, targets in tqdm(valid_loader, desc=\"Validation\"):\n",
        "                try:\n",
        "                    images = [img.to(config.DEVICE) for img in images]\n",
        "                    targets = [{k: v.to(config.DEVICE) for k, v in t.items()} for t in targets]\n",
        "\n",
        "                    # Filter out samples with no annotations\n",
        "                    valid_samples = [(img, tgt) for img, tgt in zip(images, targets) if len(tgt['boxes']) > 0]\n",
        "\n",
        "                    if len(valid_samples) == 0:\n",
        "                        continue\n",
        "\n",
        "                    images, targets = zip(*valid_samples)\n",
        "                    images = list(images)\n",
        "                    targets = list(targets)\n",
        "\n",
        "                    # Model returns loss_dict when in training mode with targets\n",
        "                    loss_dict = model(images, targets)\n",
        "                    losses = sum(loss for loss in loss_dict.values())\n",
        "                    epoch_val_loss += losses.item()\n",
        "                    val_batch_count += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"\\n‚ö† Warning: Skipping validation batch due to error: {e}\")\n",
        "                    continue\n",
        "\n",
        "        avg_val_loss = epoch_val_loss / max(val_batch_count, 1)\n",
        "        valid_losses.append(avg_val_loss)\n",
        "\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f} | Valid Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if avg_val_loss < best_loss:\n",
        "            best_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(),\n",
        "                      os.path.join(config.OUTPUT_DIR, f\"best_{model_name}_model.pth\"))\n",
        "            print(f\"  ‚úì Best model saved!\")\n",
        "\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    return train_losses, valid_losses\n",
        "\n",
        "def train_unet(model, train_loader, valid_loader, config, model_name=\"unet\"):\n",
        "    \"\"\"Train U-Net model\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TRAINING {model_name.upper()}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in range(config.NUM_EPOCHS):\n",
        "        print(f\"\\nEpoch {epoch+1}/{config.NUM_EPOCHS}\")\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        for images, targets in tqdm(train_loader, desc=\"Training\"):\n",
        "            try:\n",
        "                images = torch.stack([img.to(config.DEVICE) for img in images])\n",
        "\n",
        "                # Create combined mask from all instances\n",
        "                batch_masks = []\n",
        "                for target in targets:\n",
        "                    masks = target['masks']\n",
        "                    if len(masks) > 0:\n",
        "                        # Combine all masks for this image\n",
        "                        combined_mask = torch.clamp(masks.sum(dim=0), 0, 1).float()\n",
        "                    else:\n",
        "                        combined_mask = torch.zeros(images.shape[2], images.shape[3])\n",
        "                    batch_masks.append(combined_mask)\n",
        "\n",
        "                batch_masks = torch.stack(batch_masks).unsqueeze(1).to(config.DEVICE)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs[:, 1:2], batch_masks)  # Use tumor class output\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                batch_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"\\n‚ö† Warning: Skipping batch due to error: {e}\")\n",
        "                continue\n",
        "\n",
        "        avg_train_loss = epoch_loss / max(batch_count, 1)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        epoch_val_loss = 0\n",
        "        val_batch_count = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, targets in tqdm(valid_loader, desc=\"Validation\"):\n",
        "                try:\n",
        "                    images = torch.stack([img.to(config.DEVICE) for img in images])\n",
        "\n",
        "                    # Create combined mask\n",
        "                    batch_masks = []\n",
        "                    for target in targets:\n",
        "                        masks = target['masks']\n",
        "                        if len(masks) > 0:\n",
        "                            combined_mask = torch.clamp(masks.sum(dim=0), 0, 1).float()\n",
        "                        else:\n",
        "                            combined_mask = torch.zeros(images.shape[2], images.shape[3])\n",
        "                        batch_masks.append(combined_mask)\n",
        "\n",
        "                    batch_masks = torch.stack(batch_masks).unsqueeze(1).to(config.DEVICE)\n",
        "\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs[:, 1:2], batch_masks)\n",
        "\n",
        "                    epoch_val_loss += loss.item()\n",
        "                    val_batch_count += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"\\n‚ö† Warning: Skipping validation batch due to error: {e}\")\n",
        "                    continue\n",
        "\n",
        "        avg_val_loss = epoch_val_loss / max(val_batch_count, 1)\n",
        "        valid_losses.append(avg_val_loss)\n",
        "\n",
        "        print(f\"  Train Loss: {avg_train_loss:.4f} | Valid Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if avg_val_loss < best_loss:\n",
        "            best_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(),\n",
        "                      os.path.join(config.OUTPUT_DIR, f\"best_{model_name}_model.pth\"))\n",
        "            print(f\"  ‚úì Best model saved!\")\n",
        "\n",
        "        lr_scheduler.step()\n",
        "\n",
        "    return train_losses, valid_losses\n",
        "\n",
        "# ==================== EVALUATION ====================\n",
        "def evaluate_model(model, test_loader, config, model_type, model_name):\n",
        "    \"\"\"Evaluate model on test set with comprehensive metrics\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"EVALUATING {model_name.upper()}\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    model.eval()\n",
        "    all_ious = []\n",
        "    all_dices = []\n",
        "    all_precisions = []\n",
        "    all_recalls = []\n",
        "    all_f1_scores = []\n",
        "    predictions = []\n",
        "\n",
        "    # For ROC curve\n",
        "    all_gt_flat = []\n",
        "    all_pred_flat = []\n",
        "\n",
        "    # For confusion matrix\n",
        "    all_gt_binary = []\n",
        "    all_pred_binary = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (images, targets) in enumerate(tqdm(test_loader, desc=\"Testing\")):\n",
        "            # Clear memory every 50 batches\n",
        "            if batch_idx > 0 and batch_idx % 50 == 0:\n",
        "                clear_memory()\n",
        "\n",
        "            if model_type == \"maskrcnn\":\n",
        "                images_input = [img.to(config.DEVICE) for img in images]\n",
        "                outputs = model(images_input)\n",
        "\n",
        "                for i, output in enumerate(outputs):\n",
        "                    # Get ground truth mask\n",
        "                    gt_masks = targets[i]['masks'].cpu().numpy()\n",
        "                    if len(gt_masks) > 0:\n",
        "                        gt_mask = np.clip(gt_masks.sum(axis=0), 0, 1).astype(np.uint8)\n",
        "                    else:\n",
        "                        gt_mask = np.zeros((640, 640), dtype=np.uint8)\n",
        "\n",
        "                    # Get prediction mask\n",
        "                    if len(output['masks']) > 0:\n",
        "                        scores = output['scores'].cpu().numpy()\n",
        "                        masks = output['masks'].cpu().numpy()\n",
        "\n",
        "                        high_conf_idx = scores > config.CONFIDENCE_THRESHOLD\n",
        "                        if high_conf_idx.sum() > 0:\n",
        "                            pred_masks = masks[high_conf_idx]\n",
        "                            pred_mask = np.clip(pred_masks[:, 0].sum(axis=0), 0, 1)\n",
        "                            pred_mask_binary = (pred_mask > 0.5).astype(np.uint8)\n",
        "                        else:\n",
        "                            pred_mask = np.zeros((640, 640))\n",
        "                            pred_mask_binary = np.zeros((640, 640), dtype=np.uint8)\n",
        "                    else:\n",
        "                        pred_mask = np.zeros((640, 640))\n",
        "                        pred_mask_binary = np.zeros((640, 640), dtype=np.uint8)\n",
        "\n",
        "                    # Calculate metrics\n",
        "                    iou = calculate_iou(pred_mask_binary, gt_mask)\n",
        "                    dice = calculate_dice(pred_mask_binary, gt_mask)\n",
        "\n",
        "                    # Pixel-wise precision, recall, F1\n",
        "                    gt_flat = gt_mask.flatten()\n",
        "                    pred_flat = pred_mask_binary.flatten()\n",
        "\n",
        "                    if pred_flat.sum() > 0 or gt_flat.sum() > 0:\n",
        "                        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "                            gt_flat, pred_flat, average='binary', zero_division=0\n",
        "                        )\n",
        "                        all_precisions.append(precision)\n",
        "                        all_recalls.append(recall)\n",
        "                        all_f1_scores.append(f1)\n",
        "\n",
        "                    all_ious.append(iou)\n",
        "                    all_dices.append(dice)\n",
        "\n",
        "                    # For ROC curve - sample pixels to avoid memory issues\n",
        "                    # Only keep every 10th pixel for ROC calculation\n",
        "                    gt_flat_sampled = gt_flat[::10]\n",
        "                    pred_mask_sampled = pred_mask.flatten()[::10]\n",
        "                    all_gt_flat.extend(gt_flat_sampled)\n",
        "                    all_pred_flat.extend(pred_mask_sampled)\n",
        "\n",
        "                    # For confusion matrix - sample pixels\n",
        "                    pred_flat_sampled = pred_flat[::10]\n",
        "                    all_gt_binary.extend(gt_flat_sampled)\n",
        "                    all_pred_binary.extend(pred_flat_sampled)\n",
        "\n",
        "                    predictions.append({\n",
        "                        'image': images[i].cpu(),  # Move to CPU to free GPU memory\n",
        "                        'prediction': output,\n",
        "                        'pred_mask': pred_mask_binary,\n",
        "                        'target': targets[i],\n",
        "                        'gt_mask': gt_mask\n",
        "                    })\n",
        "\n",
        "                    # Clear variables to free memory\n",
        "                    del pred_mask, gt_flat, pred_flat\n",
        "\n",
        "            elif model_type == \"unet\":\n",
        "                # Process one image at a time to avoid memory issues\n",
        "                for i in range(len(images)):\n",
        "                    # Process single image\n",
        "                    img_input = images[i].unsqueeze(0).to(config.DEVICE)\n",
        "                    output = model(img_input)\n",
        "                    output = torch.softmax(output, dim=1)\n",
        "\n",
        "                    # Get ground truth mask\n",
        "                    gt_masks = targets[i]['masks'].cpu().numpy()\n",
        "                    if len(gt_masks) > 0:\n",
        "                        gt_mask = np.clip(gt_masks.sum(axis=0), 0, 1).astype(np.uint8)\n",
        "                    else:\n",
        "                        gt_mask = np.zeros((640, 640), dtype=np.uint8)\n",
        "\n",
        "                    # Get prediction mask\n",
        "                    pred_mask = output[0, 1].cpu().numpy()  # Tumor class\n",
        "                    pred_mask_binary = (pred_mask > 0.5).astype(np.uint8)\n",
        "\n",
        "                    # Clear GPU memory immediately\n",
        "                    del img_input, output\n",
        "                    if config.DEVICE.type == 'cuda':\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                    # Calculate metrics\n",
        "                    iou = calculate_iou(pred_mask_binary, gt_mask)\n",
        "                    dice = calculate_dice(pred_mask_binary, gt_mask)\n",
        "\n",
        "                    # Pixel-wise precision, recall, F1\n",
        "                    gt_flat = gt_mask.flatten()\n",
        "                    pred_flat = pred_mask_binary.flatten()\n",
        "\n",
        "                    if pred_flat.sum() > 0 or gt_flat.sum() > 0:\n",
        "                        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "                            gt_flat, pred_flat, average='binary', zero_division=0\n",
        "                        )\n",
        "                        all_precisions.append(precision)\n",
        "                        all_recalls.append(recall)\n",
        "                        all_f1_scores.append(f1)\n",
        "\n",
        "                    all_ious.append(iou)\n",
        "                    all_dices.append(dice)\n",
        "\n",
        "                    # For ROC curve - sample pixels to avoid memory issues\n",
        "                    # Only keep every 10th pixel for ROC calculation\n",
        "                    gt_flat_sampled = gt_flat[::10]\n",
        "                    pred_mask_sampled = pred_mask.flatten()[::10]\n",
        "                    all_gt_flat.extend(gt_flat_sampled)\n",
        "                    all_pred_flat.extend(pred_mask_sampled)\n",
        "\n",
        "                    # For confusion matrix - sample pixels\n",
        "                    pred_flat_sampled = pred_flat[::10]\n",
        "                    all_gt_binary.extend(gt_flat_sampled)\n",
        "                    all_pred_binary.extend(pred_flat_sampled)\n",
        "\n",
        "                    # Store only essential data for predictions\n",
        "                    predictions.append({\n",
        "                        'image': images[i].cpu(),  # Move to CPU immediately\n",
        "                        'prediction': None,\n",
        "                        'pred_mask': pred_mask_binary,\n",
        "                        'target': targets[i],\n",
        "                        'gt_mask': gt_mask\n",
        "                    })\n",
        "\n",
        "                    # Clear variables\n",
        "                    del pred_mask, gt_flat, pred_flat\n",
        "\n",
        "    # Calculate mean metrics\n",
        "    results = {\n",
        "        'mean_iou': np.mean(all_ious) if all_ious else 0,\n",
        "        'std_iou': np.std(all_ious) if all_ious else 0,\n",
        "        'mean_dice': np.mean(all_dices) if all_dices else 0,\n",
        "        'std_dice': np.std(all_dices) if all_dices else 0,\n",
        "        'mean_precision': np.mean(all_precisions) if all_precisions else 0,\n",
        "        'std_precision': np.std(all_precisions) if all_precisions else 0,\n",
        "        'mean_recall': np.mean(all_recalls) if all_recalls else 0,\n",
        "        'std_recall': np.std(all_recalls) if all_recalls else 0,\n",
        "        'mean_f1': np.mean(all_f1_scores) if all_f1_scores else 0,\n",
        "        'std_f1': np.std(all_f1_scores) if all_f1_scores else 0,\n",
        "        'all_ious': all_ious,\n",
        "        'all_dices': all_dices,\n",
        "        'all_precisions': all_precisions,\n",
        "        'all_recalls': all_recalls,\n",
        "        'all_f1_scores': all_f1_scores,\n",
        "        'all_gt_flat': all_gt_flat,\n",
        "        'all_pred_flat': all_pred_flat,\n",
        "        'all_gt_binary': all_gt_binary,\n",
        "        'all_pred_binary': all_pred_binary\n",
        "    }\n",
        "\n",
        "    print(f\"\\n‚úì Evaluation Results for {model_name.upper()}:\")\n",
        "    print(f\"  Mean IoU: {results['mean_iou']:.4f} ¬± {results['std_iou']:.4f}\")\n",
        "    print(f\"  Mean Dice: {results['mean_dice']:.4f} ¬± {results['std_dice']:.4f}\")\n",
        "    print(f\"  Mean Precision: {results['mean_precision']:.4f} ¬± {results['std_precision']:.4f}\")\n",
        "    print(f\"  Mean Recall: {results['mean_recall']:.4f} ¬± {results['std_recall']:.4f}\")\n",
        "    print(f\"  Mean F1-Score: {results['mean_f1']:.4f} ¬± {results['std_f1']:.4f}\")\n",
        "    print(f\"  Tested on {len(test_loader.dataset)} images\")\n",
        "\n",
        "    return results, predictions\n",
        "\n",
        "# ==================== PUBLICATION-READY VISUALIZATIONS ====================\n",
        "def plot_model_comparison(results_dict, config):\n",
        "    \"\"\"Create publication-ready model comparison plots\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"CREATING MODEL COMPARISON VISUALIZATIONS\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Set publication style\n",
        "    plt.style.use('seaborn-v0_8-paper')\n",
        "    plt.rcParams.update({\n",
        "        'font.size': 12,\n",
        "        'font.family': 'serif',\n",
        "        'font.serif': ['Times New Roman'],\n",
        "        'axes.labelsize': 14,\n",
        "        'axes.titlesize': 16,\n",
        "        'xtick.labelsize': 12,\n",
        "        'ytick.labelsize': 12,\n",
        "        'legend.fontsize': 12,\n",
        "        'figure.dpi': 300\n",
        "    })\n",
        "\n",
        "    model_names = list(results_dict.keys())\n",
        "\n",
        "    # 1. Bar plot comparing metrics with error bars and significance\n",
        "    metrics = ['mean_iou', 'mean_dice', 'mean_precision', 'mean_recall', 'mean_f1']\n",
        "    metric_labels = ['IoU', 'Dice', 'Precision', 'Recall', 'F1-Score']\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    x = np.arange(len(metric_labels))\n",
        "    width = 0.35\n",
        "\n",
        "    colors = ['#2E86AB', '#A23B72']  # Professional color scheme\n",
        "\n",
        "    for i, model_name in enumerate(model_names):\n",
        "        means = [results_dict[model_name]['results'][m] for m in metrics]\n",
        "        stds = [results_dict[model_name]['results'][m.replace('mean_', 'std_')] for m in metrics]\n",
        "\n",
        "        bars = ax.bar(x + i*width, means, width, yerr=stds, label=model_name.upper(),\n",
        "                     color=colors[i], alpha=0.8, capsize=5, error_kw={'linewidth': 2})\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                   f'{height:.3f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "    ax.set_xlabel('Metrics', fontweight='bold')\n",
        "    ax.set_ylabel('Score', fontweight='bold')\n",
        "    ax.set_title('Model Performance Comparison', fontweight='bold', pad=20)\n",
        "    ax.set_xticks(x + width / 2)\n",
        "    ax.set_xticklabels(metric_labels)\n",
        "    ax.legend(loc='lower right', frameon=True, shadow=True)\n",
        "    ax.set_ylim(0, 1.1)\n",
        "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, \"Fig1_Model_Comparison.png\"), dpi=300, bbox_inches='tight')\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, \"Fig1_Model_Comparison.pdf\"), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"‚úì Fig1: Model comparison saved (PNG + PDF)\")\n",
        "\n",
        "    # 2. Statistical significance testing with box plots\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    metrics_for_test = ['all_ious', 'all_dices', 'all_precisions', 'all_recalls', 'all_f1_scores']\n",
        "    metric_titles = ['IoU', 'Dice Coefficient', 'Precision', 'Recall', 'F1-Score']\n",
        "\n",
        "    p_values = {}\n",
        "\n",
        "    for idx, (metric, title) in enumerate(zip(metrics_for_test, metric_titles)):\n",
        "        data_to_plot = [results_dict[model_name]['results'][metric] for model_name in model_names]\n",
        "\n",
        "        # Create box plot\n",
        "        bp = axes[idx].boxplot(data_to_plot, labels=[m.upper() for m in model_names],\n",
        "                               patch_artist=True, widths=0.6)\n",
        "\n",
        "        # Color boxes\n",
        "        for patch, color in zip(bp['boxes'], colors):\n",
        "            patch.set_facecolor(color)\n",
        "            patch.set_alpha(0.7)\n",
        "\n",
        "        # Statistical test (Wilcoxon signed-rank test for paired samples)\n",
        "        if len(model_names) == 2:\n",
        "            stat, p_val = stats.wilcoxon(data_to_plot[0], data_to_plot[1])\n",
        "            p_values[metric] = p_val\n",
        "\n",
        "            # Add significance annotation\n",
        "            y_max = max([max(d) for d in data_to_plot])\n",
        "            y_pos = y_max * 1.05\n",
        "\n",
        "            if p_val < 0.001:\n",
        "                sig_text = '***'\n",
        "            elif p_val < 0.01:\n",
        "                sig_text = '**'\n",
        "            elif p_val < 0.05:\n",
        "                sig_text = '*'\n",
        "            else:\n",
        "                sig_text = 'ns'\n",
        "\n",
        "            axes[idx].plot([1, 2], [y_pos, y_pos], 'k-', linewidth=1.5)\n",
        "            axes[idx].text(1.5, y_pos*1.02, f'p={p_val:.4f}\\n{sig_text}',\n",
        "                          ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "        axes[idx].set_title(title, fontweight='bold', pad=10)\n",
        "        axes[idx].set_ylabel('Score', fontweight='bold')\n",
        "        axes[idx].grid(axis='y', alpha=0.3, linestyle='--')\n",
        "        axes[idx].spines['top'].set_visible(False)\n",
        "        axes[idx].spines['right'].set_visible(False)\n",
        "\n",
        "    # Remove empty subplot\n",
        "    fig.delaxes(axes[5])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, \"Fig2_Statistical_Comparison.png\"), dpi=300, bbox_inches='tight')\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, \"Fig2_Statistical_Comparison.pdf\"), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"‚úì Fig2: Statistical comparison with p-values saved (PNG + PDF)\")\n",
        "\n",
        "    return p_values\n",
        "\n",
        "def plot_roc_curves(results_dict, config):\n",
        "    \"\"\"Plot ROC curves for all models\"\"\"\n",
        "    print(\"\\nCreating ROC curves...\")\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    colors = ['#2E86AB', '#A23B72']\n",
        "\n",
        "    for idx, (model_name, data) in enumerate(results_dict.items()):\n",
        "        y_true = data['results']['all_gt_flat']\n",
        "        y_scores = data['results']['all_pred_flat']\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=colors[idx], lw=3, alpha=0.8,\n",
        "                label=f'{model_name.upper()} (AUC = {roc_auc:.3f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, alpha=0.5, label='Random Classifier')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate', fontweight='bold', fontsize=14)\n",
        "    plt.ylabel('True Positive Rate', fontweight='bold', fontsize=14)\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve', fontweight='bold', fontsize=16, pad=20)\n",
        "    plt.legend(loc=\"lower right\", frameon=True, shadow=True, fontsize=12)\n",
        "    plt.grid(alpha=0.3, linestyle='--')\n",
        "    plt.gca().spines['top'].set_visible(False)\n",
        "    plt.gca().spines['right'].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, \"Fig3_ROC_Curves.png\"), dpi=300, bbox_inches='tight')\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, \"Fig3_ROC_Curves.pdf\"), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"‚úì Fig3: ROC curves saved (PNG + PDF)\")\n",
        "\n",
        "def plot_confusion_matrices(results_dict, config):\n",
        "    \"\"\"Plot confusion matrices for all models\"\"\"\n",
        "    print(\"\\nCreating confusion matrices...\")\n",
        "\n",
        "    n_models = len(results_dict)\n",
        "    fig, axes = plt.subplots(1, n_models, figsize=(7*n_models, 6))\n",
        "\n",
        "    if n_models == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for idx, (model_name, data) in enumerate(results_dict.items()):\n",
        "        y_true = data['results']['all_gt_binary']\n",
        "        y_pred = data['results']['all_pred_binary']\n",
        "\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "        # Normalize confusion matrix\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        # Plot\n",
        "        im = axes[idx].imshow(cm_normalized, interpolation='nearest', cmap='Blues')\n",
        "        axes[idx].set_title(f'{model_name.upper()}', fontweight='bold', fontsize=14, pad=10)\n",
        "\n",
        "        # Add colorbar\n",
        "        cbar = plt.colorbar(im, ax=axes[idx], fraction=0.046, pad=0.04)\n",
        "        cbar.set_label('Normalized Frequency', fontweight='bold')\n",
        "\n",
        "        # Add text annotations\n",
        "        thresh = cm_normalized.max() / 2.\n",
        "        for i in range(cm.shape[0]):\n",
        "            for j in range(cm.shape[1]):\n",
        "                axes[idx].text(j, i, f'{cm[i, j]:,}\\n({cm_normalized[i, j]:.2%})',\n",
        "                             ha=\"center\", va=\"center\", fontsize=12, fontweight='bold',\n",
        "                             color=\"white\" if cm_normalized[i, j] > thresh else \"black\")\n",
        "\n",
        "        axes[idx].set_ylabel('True Label', fontweight='bold', fontsize=12)\n",
        "        axes[idx].set_xlabel('Predicted Label', fontweight='bold', fontsize=12)\n",
        "        axes[idx].set_xticks([0, 1])\n",
        "        axes[idx].set_yticks([0, 1])\n",
        "        axes[idx].set_xticklabels(['Background', 'Tumor'])\n",
        "        axes[idx].set_yticklabels(['Background', 'Tumor'])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, \"Fig4_Confusion_Matrices.png\"), dpi=300, bbox_inches='tight')\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, \"Fig4_Confusion_Matrices.pdf\"), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"‚úì Fig4: Confusion matrices saved (PNG + PDF)\")\n",
        "\n",
        "def plot_training_curves_comparison(results_dict, config):\n",
        "    \"\"\"Plot training curves for all models\"\"\"\n",
        "    print(\"\\nCreating training curves comparison...\")\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    colors = ['#2E86AB', '#A23B72']\n",
        "\n",
        "    for idx, (model_name, data) in enumerate(results_dict.items()):\n",
        "        epochs = range(1, len(data['train_losses']) + 1)\n",
        "\n",
        "        ax1.plot(epochs, data['train_losses'], color=colors[idx], linewidth=2.5,\n",
        "                alpha=0.8, label=model_name.upper(), marker='o', markersize=4, markevery=5)\n",
        "        ax2.plot(epochs, data['valid_losses'], color=colors[idx], linewidth=2.5,\n",
        "                alpha=0.8, label=model_name.upper(), marker='s', markersize=4, markevery=5)\n",
        "\n",
        "    ax1.set_xlabel('Epoch', fontweight='bold', fontsize=12)\n",
        "    ax1.set_ylabel('Loss', fontweight='bold', fontsize=12)\n",
        "    ax1.set_title('Training Loss', fontweight='bold', fontsize=14, pad=10)\n",
        "    ax1.legend(frameon=True, shadow=True)\n",
        "    ax1.grid(alpha=0.3, linestyle='--')\n",
        "    ax1.spines['top'].set_visible(False)\n",
        "    ax1.spines['right'].set_visible(False)\n",
        "\n",
        "    ax2.set_xlabel('Epoch', fontweight='bold', fontsize=12)\n",
        "    ax2.set_ylabel('Loss', fontweight='bold', fontsize=12)\n",
        "    ax2.set_title('Validation Loss', fontweight='bold', fontsize=14, pad=10)\n",
        "    ax2.legend(frameon=True, shadow=True)\n",
        "    ax2.grid(alpha=0.3, linestyle='--')\n",
        "    ax2.spines['top'].set_visible(False)\n",
        "    ax2.spines['right'].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, \"Fig5_Training_Curves.png\"), dpi=300, bbox_inches='tight')\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, \"Fig5_Training_Curves.pdf\"), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"‚úì Fig5: Training curves comparison saved (PNG + PDF)\")\n",
        "\n",
        "def visualize_predictions(predictions, config, model_name, num_samples=10):\n",
        "    \"\"\"Visualize model predictions\"\"\"\n",
        "    print(f\"\\nCreating prediction visualizations for {model_name.upper()}...\")\n",
        "\n",
        "    num_samples = min(num_samples, len(predictions))\n",
        "    indices = np.random.choice(len(predictions), num_samples, replace=False)\n",
        "\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
        "    if num_samples == 1:\n",
        "        axes = axes.reshape(1, -1)\n",
        "\n",
        "    for idx, pred_idx in enumerate(indices):\n",
        "        pred = predictions[pred_idx]\n",
        "\n",
        "        # Original image\n",
        "        img = pred['image'].cpu().permute(1, 2, 0).numpy()\n",
        "        axes[idx, 0].imshow(img)\n",
        "        axes[idx, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
        "        axes[idx, 0].axis('off')\n",
        "\n",
        "        # Ground truth\n",
        "        gt_mask = pred['gt_mask']\n",
        "        gt_overlay = img.copy()\n",
        "        gt_overlay[gt_mask > 0] = [0, 1, 0]  # Green\n",
        "        axes[idx, 1].imshow(gt_overlay)\n",
        "        axes[idx, 1].set_title('Ground Truth', fontsize=12, fontweight='bold')\n",
        "        axes[idx, 1].axis('off')\n",
        "\n",
        "        # Prediction\n",
        "        pred_mask = pred['pred_mask']\n",
        "        pred_overlay = img.copy()\n",
        "        pred_overlay[pred_mask > 0] = [1, 0, 0]  # Red\n",
        "        axes[idx, 2].imshow(pred_overlay)\n",
        "\n",
        "        # Calculate IoU and Dice for this sample\n",
        "        iou = calculate_iou(pred_mask, gt_mask)\n",
        "        dice = calculate_dice(pred_mask, gt_mask)\n",
        "        axes[idx, 2].set_title(f'Prediction\\nIoU: {iou:.3f}, Dice: {dice:.3f}',\n",
        "                              fontsize=12, fontweight='bold')\n",
        "        axes[idx, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(config.OUTPUT_DIR, f\"Fig6_{model_name}_Predictions.png\"), dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"‚úì Fig6: {model_name.upper()} predictions saved (PNG)\")\n",
        "\n",
        "def save_results_to_excel(results_dict, p_values, config):\n",
        "    \"\"\"Save all results to Excel files\"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"CREATING EXCEL FILES\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # 1. Summary metrics table\n",
        "    summary_data = []\n",
        "    for model_name, data in results_dict.items():\n",
        "        results = data['results']\n",
        "        summary_data.append({\n",
        "            'Model': model_name.upper(),\n",
        "            'IoU_Mean': results['mean_iou'],\n",
        "            'IoU_Std': results['std_iou'],\n",
        "            'Dice_Mean': results['mean_dice'],\n",
        "            'Dice_Std': results['std_dice'],\n",
        "            'Precision_Mean': results['mean_precision'],\n",
        "            'Precision_Std': results['std_precision'],\n",
        "            'Recall_Mean': results['mean_recall'],\n",
        "            'Recall_Std': results['std_recall'],\n",
        "            'F1_Mean': results['mean_f1'],\n",
        "            'F1_Std': results['std_f1'],\n",
        "            'Best_Train_Loss': min(data['train_losses']),\n",
        "            'Best_Valid_Loss': min(data['valid_losses']),\n",
        "            'Final_Train_Loss': data['train_losses'][-1],\n",
        "            'Final_Valid_Loss': data['valid_losses'][-1]\n",
        "        })\n",
        "\n",
        "    df_summary = pd.DataFrame(summary_data)\n",
        "\n",
        "    # 2. P-values table\n",
        "    p_values_data = []\n",
        "    for metric, p_val in p_values.items():\n",
        "        metric_name = metric.replace('all_', '').replace('_', ' ').title()\n",
        "        significance = ''\n",
        "        if p_val < 0.001:\n",
        "            significance = '***'\n",
        "        elif p_val < 0.01:\n",
        "            significance = '**'\n",
        "        elif p_val < 0.05:\n",
        "            significance = '*'\n",
        "        else:\n",
        "            significance = 'ns'\n",
        "\n",
        "        p_values_data.append({\n",
        "            'Metric': metric_name,\n",
        "            'P_Value': p_val,\n",
        "            'Significance': significance,\n",
        "            'Interpretation': 'Significant' if p_val < 0.05 else 'Not Significant'\n",
        "        })\n",
        "\n",
        "    df_pvalues = pd.DataFrame(p_values_data)\n",
        "\n",
        "    # 3. Detailed per-image metrics for each model\n",
        "    detailed_dfs = {}\n",
        "    for model_name, data in results_dict.items():\n",
        "        results = data['results']\n",
        "        detailed_data = {\n",
        "            'Image_Index': range(1, len(results['all_ious']) + 1),\n",
        "            'IoU': results['all_ious'],\n",
        "            'Dice': results['all_dices'],\n",
        "            'Precision': results['all_precisions'] if results['all_precisions'] else [0]*len(results['all_ious']),\n",
        "            'Recall': results['all_recalls'] if results['all_recalls'] else [0]*len(results['all_ious']),\n",
        "            'F1_Score': results['all_f1_scores'] if results['all_f1_scores'] else [0]*len(results['all_ious'])\n",
        "        }\n",
        "        detailed_dfs[model_name] = pd.DataFrame(detailed_data)\n",
        "\n",
        "    # 4. Training history for each model\n",
        "    training_dfs = {}\n",
        "    for model_name, data in results_dict.items():\n",
        "        training_data = {\n",
        "            'Epoch': range(1, len(data['train_losses']) + 1),\n",
        "            'Training_Loss': data['train_losses'],\n",
        "            'Validation_Loss': data['valid_losses']\n",
        "        }\n",
        "        training_dfs[model_name] = pd.DataFrame(training_data)\n",
        "\n",
        "    # Save to Excel with multiple sheets\n",
        "    excel_path = os.path.join(config.OUTPUT_DIR, \"Table1_Model_Results_Summary.xlsx\")\n",
        "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
        "        df_summary.to_excel(writer, sheet_name='Summary_Metrics', index=False)\n",
        "        df_pvalues.to_excel(writer, sheet_name='Statistical_Tests', index=False)\n",
        "\n",
        "        for model_name, df in detailed_dfs.items():\n",
        "            sheet_name = f'{model_name.upper()}_Detailed'\n",
        "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "        for model_name, df in training_dfs.items():\n",
        "            sheet_name = f'{model_name.upper()}_Training'\n",
        "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "    print(f\"‚úì Table1: Comprehensive results saved to Excel\")\n",
        "    print(f\"  File: Table1_Model_Results_Summary.xlsx\")\n",
        "    print(f\"  Sheets: Summary_Metrics, Statistical_Tests, Detailed metrics, Training history\")\n",
        "\n",
        "    # Also save individual CSV files for easy access\n",
        "    df_summary.to_csv(os.path.join(config.OUTPUT_DIR, \"Table2_Summary_Metrics.csv\"), index=False)\n",
        "    df_pvalues.to_csv(os.path.join(config.OUTPUT_DIR, \"Table3_P_Values.csv\"), index=False)\n",
        "    print(f\"‚úì Table2 & Table3: CSV files saved\")\n",
        "\n",
        "    return df_summary, df_pvalues\n",
        "\n",
        "# ==================== MAIN EXECUTION ====================\n",
        "def main():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"LOADING DATASET\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Check if data exists\n",
        "    if not os.path.exists(config.DATA_DIR):\n",
        "        print(f\"\\n‚ö† ERROR: Data directory not found: {config.DATA_DIR}\")\n",
        "        print(\"Please update the DATA_DIR path in the Config class\")\n",
        "        return\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = TumorSegmentationDataset(config.TRAIN_IMAGES, config.TRAIN_ANNOTATIONS)\n",
        "    valid_dataset = TumorSegmentationDataset(config.VALID_IMAGES, config.VALID_ANNOTATIONS)\n",
        "    test_dataset = TumorSegmentationDataset(config.TEST_IMAGES, config.TEST_ANNOTATIONS)\n",
        "\n",
        "    print(f\"\\n‚úì Dataset loaded:\")\n",
        "    print(f\"  Training: {len(train_dataset)} images\")\n",
        "    print(f\"  Validation: {len(valid_dataset)} images\")\n",
        "    print(f\"  Testing: {len(test_dataset)} images\")\n",
        "\n",
        "    # Create data loaders\n",
        "    def collate_fn(batch):\n",
        "        return tuple(zip(*batch))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=config.BATCH_SIZE,\n",
        "                             shuffle=False, collate_fn=collate_fn, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1,\n",
        "                            shuffle=False, collate_fn=collate_fn, num_workers=0)\n",
        "\n",
        "    # Dictionary to store results for all models\n",
        "    results_dict = {}\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    for model_type in config.MODELS_TO_TRAIN:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"INITIALIZING {model_type.upper()} MODEL\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        model = get_model(model_type, config.NUM_CLASSES, config.DEVICE)\n",
        "        print(f\"\\n‚úì Model created and moved to {config.DEVICE}\")\n",
        "\n",
        "        # Train model\n",
        "        if model_type == \"maskrcnn\":\n",
        "            train_losses, valid_losses = train_maskrcnn(model, train_loader, valid_loader, config, model_type)\n",
        "        elif model_type == \"unet\":\n",
        "            train_losses, valid_losses = train_unet(model, train_loader, valid_loader, config, model_type)\n",
        "        else:\n",
        "            print(f\"‚ö† Warning: Unknown model type {model_type}, skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Load best model\n",
        "        model.load_state_dict(torch.load(os.path.join(config.OUTPUT_DIR, f\"best_{model_type}_model.pth\")))\n",
        "\n",
        "        # Evaluate\n",
        "        results, predictions = evaluate_model(model, test_loader, config, model_type, model_type)\n",
        "\n",
        "        # Visualize predictions for this model\n",
        "        visualize_predictions(predictions, config, model_type, num_samples=10)\n",
        "\n",
        "        # Store results\n",
        "        results_dict[model_type] = {\n",
        "            'results': results,\n",
        "            'predictions': predictions,\n",
        "            'train_losses': train_losses,\n",
        "            'valid_losses': valid_losses\n",
        "        }\n",
        "\n",
        "        # Aggressive memory cleanup\n",
        "        del model, results, predictions, train_losses, valid_losses\n",
        "        clear_memory()\n",
        "\n",
        "        print(f\"\\n‚úì Memory cleared after {model_type.upper()}\")\n",
        "\n",
        "    # ==================== COMPARATIVE ANALYSIS ====================\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"COMPARATIVE ANALYSIS\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    # Create all publication-ready visualizations\n",
        "    p_values = plot_model_comparison(results_dict, config)\n",
        "    plot_roc_curves(results_dict, config)\n",
        "    plot_confusion_matrices(results_dict, config)\n",
        "    plot_training_curves_comparison(results_dict, config)\n",
        "\n",
        "    # Save results to Excel\n",
        "    df_summary, df_pvalues = save_results_to_excel(results_dict, p_values, config)\n",
        "\n",
        "    # Print comparison summary\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"MODEL COMPARISON SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    print(\"\\nüìä PERFORMANCE METRICS (Mean ¬± Std):\")\n",
        "    print(\"=\"*60)\n",
        "    for model_name, data in results_dict.items():\n",
        "        results = data['results']\n",
        "        print(f\"\\n{model_name.upper()}:\")\n",
        "        print(f\"  IoU:       {results['mean_iou']:.4f} ¬± {results['std_iou']:.4f}\")\n",
        "        print(f\"  Dice:      {results['mean_dice']:.4f} ¬± {results['std_dice']:.4f}\")\n",
        "        print(f\"  Precision: {results['mean_precision']:.4f} ¬± {results['std_precision']:.4f}\")\n",
        "        print(f\"  Recall:    {results['mean_recall']:.4f} ¬± {results['std_recall']:.4f}\")\n",
        "        print(f\"  F1-Score:  {results['mean_f1']:.4f} ¬± {results['std_f1']:.4f}\")\n",
        "\n",
        "    print(f\"\\nüìà STATISTICAL SIGNIFICANCE (Wilcoxon Signed-Rank Test):\")\n",
        "    print(\"=\"*60)\n",
        "    for metric, p_val in p_values.items():\n",
        "        metric_name = metric.replace('all_', '').replace('_', ' ').title()\n",
        "        if p_val < 0.001:\n",
        "            sig = '*** (p < 0.001) - Highly Significant'\n",
        "        elif p_val < 0.01:\n",
        "            sig = '** (p < 0.01) - Very Significant'\n",
        "        elif p_val < 0.05:\n",
        "            sig = '* (p < 0.05) - Significant'\n",
        "        else:\n",
        "            sig = 'ns (not significant)'\n",
        "        print(f\"  {metric_name:20s}: p = {p_val:.6f}  {sig}\")\n",
        "\n",
        "    # Create ZIP file\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"CREATING ZIP FILE\")\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    zip_filename = f\"TumorSegmentation_Comparison_{timestamp}\"\n",
        "\n",
        "    try:\n",
        "        shutil.make_archive(zip_filename, 'zip', config.OUTPUT_DIR)\n",
        "        zip_size = os.path.getsize(f\"{zip_filename}.zip\") / (1024 * 1024)\n",
        "\n",
        "        print(f\"\\n‚úì ZIP file created successfully!\")\n",
        "        print(f\"  File name: {zip_filename}.zip\")\n",
        "        print(f\"  File size: {zip_size:.2f} MB\")\n",
        "        print(f\"  Location: {os.path.abspath(zip_filename + '.zip')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ö† Error creating ZIP file: {e}\")\n",
        "\n",
        "    # Final Summary\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"FINAL SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"‚úì Models trained: {', '.join([m.upper() for m in config.MODELS_TO_TRAIN])}\")\n",
        "    print(f\"‚úì Training completed: {config.NUM_EPOCHS} epochs per model\")\n",
        "    print(f\"‚úì Test images evaluated: {len(test_dataset)}\")\n",
        "    print(f\"\\nüìä PUBLICATION-READY OUTPUTS GENERATED:\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"  FIGURES (PNG + PDF):\")\n",
        "    print(\"    ‚Ä¢ Fig1_Model_Comparison.png/.pdf - Bar plots with error bars\")\n",
        "    print(\"    ‚Ä¢ Fig2_Statistical_Comparison.png/.pdf - Box plots with p-values\")\n",
        "    print(\"    ‚Ä¢ Fig3_ROC_Curves.png/.pdf - ROC curves with AUC\")\n",
        "    print(\"    ‚Ä¢ Fig4_Confusion_Matrices.png/.pdf - Normalized confusion matrices\")\n",
        "    print(\"    ‚Ä¢ Fig5_Training_Curves.png/.pdf - Training/validation loss comparison\")\n",
        "    print(\"    ‚Ä¢ Fig6_MASKRCNN_Predictions.png - Sample predictions (Mask R-CNN)\")\n",
        "    print(\"    ‚Ä¢ Fig6_UNET_Predictions.png - Sample predictions (U-Net)\")\n",
        "    print(\"\\n  TABLES (EXCEL + CSV):\")\n",
        "    print(\"    ‚Ä¢ Table1_Model_Results_Summary.xlsx - Multi-sheet comprehensive results\")\n",
        "    print(\"      - Summary_Metrics: Mean and std for all metrics\")\n",
        "    print(\"      - Statistical_Tests: P-values and significance\")\n",
        "    print(\"      - MASKRCNN_Detailed: Per-image metrics\")\n",
        "    print(\"      - UNET_Detailed: Per-image metrics\")\n",
        "    print(\"      - MASKRCNN_Training: Epoch-wise loss values\")\n",
        "    print(\"      - UNET_Training: Epoch-wise loss values\")\n",
        "    print(\"    ‚Ä¢ Table2_Summary_Metrics.csv - Quick summary table\")\n",
        "    print(\"    ‚Ä¢ Table3_P_Values.csv - Statistical test results\")\n",
        "    print(\"\\n  MODEL WEIGHTS:\")\n",
        "    print(\"    ‚Ä¢ best_maskrcnn_model.pth - Trained Mask R-CNN model\")\n",
        "    print(\"    ‚Ä¢ best_unet_model.pth - Trained U-Net model\")\n",
        "    print(\"\\n‚úÖ All results ready for publication!\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
